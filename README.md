# kaggle-titanic
For the classic Titanic competition at Kaggle. When I run it I got an accuracy of 78.708 %.

Prediction made by a multi-model approach combining the result of Random Forest, XGBoost, K-Nearest Neighbors, Logistic Regression and Support Vector Machine models trained using scikit-learn. Some handling of missing values and feature engineering.
